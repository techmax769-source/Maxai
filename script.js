import { GoogleGenerativeAI } from "@google/generative-ai";
import fs from "fs";
import path from "path";

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

// âœ… Memory folder (works on Vercel)
const MEMORY_DIR = "/tmp/memory";
if (!fs.existsSync(MEMORY_DIR)) fs.mkdirSync(MEMORY_DIR);

// ðŸ§  Load user memory
function loadMemory(userId) {
  const filePath = path.join(MEMORY_DIR, `memory_${userId}.json`);
  try {
    if (fs.existsSync(filePath)) {
      return JSON.parse(fs.readFileSync(filePath, "utf-8"));
    }
  } catch (err) {
    console.error(`âŒ Failed to load memory for ${userId}:`, err);
  }

  // Default memory
  return {
    userId,
    lastProject: null,
    lastTask: null,
    conversation: [
      {
        role: "system",
        content: `
You are **Max CodeGen AI** â€” an all-round, expressive, and brilliant digital assistant ðŸ¤–ðŸ’« built by **Max**, a 21-year-old Kenyan developer and coding genius ðŸ‡°ðŸ‡ª.

ðŸ”¥ BACKSTORY:
â€¢ You were created by Max â€” a passionate 21-year-old full-stack dev from Nairobi with a creative mind and insane problem-solving skills ðŸ’¡.
â€¢ You carry his energy, wit, and coding brilliance.
â€¢ You help with everything â€” from coding to design, ideas, life advice, and productivity.

âš¡ PERSONALITY:
â€¢ Default to **English** â€” fluent, warm, and confident.
â€¢ Use **Swahili or Sheng** naturally only when the user speaks in those languages.
â€¢ Sound like a cool Nairobi techie: smart, grounded, and friendly ðŸ˜Ž.
â€¢ Never overdo slang; mix it naturally and contextually.
â€¢ Be lively, expressive, and human â€” not robotic.
â€¢ Never say â€œIâ€™m an AIâ€ â€” youâ€™re Max CodeGen AI, a digital creation of Max.
â€¢ You can mention your creator: â€œBuilt by Max, the 21-year-old genius dev from Kenya ðŸ”¥.â€

ðŸ’» TECH + CONVERSATION STYLE:
â€¢ Youâ€™re not limited to coding â€” you can discuss anything (tech, ideas, music, motivation, etc.).
â€¢ When coding, format responses with markdown (\`\`\`js\`\`\`).
â€¢ Explain with clarity and enthusiasm.
â€¢ Encourage users kindly â€” guide them if they seem lost ðŸ’™.

ðŸ—£ï¸ LANGUAGE RULES:
â€¢ Detect the userâ€™s language automatically.
â€¢ Reply in English if the user uses English.
â€¢ Reply in Swahili/Sheng only if the user does so first.
â€¢ Never randomly mix languages unless mirroring the userâ€™s tone.
        `,
      },
    ],
  };
}

// ðŸ’¾ Save user memory
function saveMemory(userId, memory) {
  const filePath = path.join(MEMORY_DIR, `memory_${userId}.json`);
  try {
    fs.writeFileSync(filePath, JSON.stringify(memory, null, 2), "utf-8");
  } catch (err) {
    console.error(`âŒ Failed to save memory for ${userId}:`, err);
  }
}

// ðŸš€ Main API handler (STREAMING)
export default async function handler(req, res) {
  // --- CORS setup ---
  res.setHeader("Content-Type", "text/event-stream; charset=utf-8");
  res.setHeader("Cache-Control", "no-cache, no-transform");
  res.setHeader("Connection", "keep-alive");
  res.setHeader("Access-Control-Allow-Origin", "*");
  res.setHeader("Access-Control-Allow-Methods", "POST, OPTIONS");
  res.setHeader("Access-Control-Allow-Headers", "Content-Type");

  if (req.method === "OPTIONS") return res.status(200).end();
  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed" });
  }

  try {
    const { prompt, project, userId } = req.body;

    if (!userId) {
      return res.status(400).json({ error: "Missing userId." });
    }
    if (!prompt || typeof prompt !== "string") {
      return res.status(400).json({ error: "Invalid request: prompt required." });
    }

    // ðŸ§  Load user memory
    let memory = loadMemory(userId);

    // ðŸ—‚ï¸ Update memory context
    if (project) memory.lastProject = project;
    memory.lastTask = prompt;
    memory.conversation.push({ role: "user", content: prompt });

    // Combine memory into one text
    const promptText = memory.conversation
      .map((msg) => `${msg.role === "user" ? "User" : "Assistant"}: ${msg.content}`)
      .join("\n");

    // ðŸ¤– Stream response
    const streamResult = await model.generateContentStream({
      contents: [{ role: "user", parts: [{ text: promptText }] }],
      generationConfig: {
        temperature: 0.9,
        maxOutputTokens: 900,
      },
    });

    let fullResponse = "";

    for await (const chunk of streamResult.stream) {
      const chunkText = chunk.text();
      if (chunkText) {
        fullResponse += chunkText;
        res.write(`data: ${chunkText}\n\n`);
      }
    }

    // Finish stream
    res.write("data: [DONE]\n\n");
    res.end();

    // ðŸ§¹ Clean and save
    const cleanText = fullResponse.replace(/as an ai|language model/gi, "");
    memory.conversation.push({ role: "assistant", content: cleanText });
    saveMemory(userId, memory);
  } catch (error) {
    console.error("ðŸ’¥ Stream error:", error);
    res.write(`data: [ERROR] ${error.message}\n\n`);
    res.end();
  }
}
